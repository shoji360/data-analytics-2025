{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453f1d82-5bd6-4717-a8ba-3039879faf2b",
   "metadata": {},
   "source": [
    "# Day 1: BadData, not BigData\n",
    "データサイエンスという言葉が世を賑わせており，統計処理や機械学習に関する書籍や講義にもアクセスしやすくなってきた．それらを分析手法を十分に学習した学生は，就職後，データサイエンティストとして大活躍だろう，か？\n",
    "\n",
    "残念ながらそう甘くはない．統計処理や機械学習の講義や書籍で扱われている手法はたいていの場合はキレイなサンプルデータである．一方で，企業や一般社会の中で料理（分析）されるのを待っている大量のデータは分析に適した形になっていない．ビッグデータ（BigData）ではなくバッドデータ（BadData）であることが大半である．データサイエンスの概念が導入されていない現場であればあるほど，バッドデータに遭遇する可能性は高い．分析手法しか習っていない新米データサイエンティストは，バッドデータに対峙して困ることになる．\n",
    "\n",
    "Day 1では，（仮想的な）ある小売店（仮称：杏森堂）の売上データを取り上げ，バッドデータの分析（の大変さ）を体験する．この体験を通じて，\n",
    "* データサイエンス活動における前処理プロセスの必要性\n",
    "* データのデザインの重要性\n",
    "\n",
    "について感じてもらいたい．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f690937-b36d-4e4c-ab9a-aeb66d87a8cb",
   "metadata": {},
   "source": [
    "## 演習環境\n",
    "Day 1 の演習では，Excelファイルのデータ分析を行う．基本的には _Excel_ を用いた演習を行うが，Excelデータを[Python](https://www.python.jp)や[R](https://www.r-project.org/)などを用いてデータ処理したい（できる）学生はそれらを用いても構わない．\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f3931-0874-41aa-b5b5-06bf9c21de7e",
   "metadata": {},
   "source": [
    "## 課題0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52996c-0b17-4d49-842f-a82615a52f3f",
   "metadata": {},
   "source": [
    "杏森堂では，顧客台帳をExcelフォーマットを使って管理している．売上は順調であり，Excelのデータがかなりのボリュームになっているため，データ分析を行うことで色々な知見が期待できる．\n",
    "\n",
    "杏森堂からデータ分析の依頼を受けたとしよう．[このZipファイル](https://shoji-lab.jp/day1-dataset.zip)には，杏森堂の売上に関する以下の4つのファイルが格納されている：\n",
    "* 購買記録に関するデータ（2019年1月〜2019年7月の売上履歴）\n",
    "    * uriage_1.csv\n",
    "    * uriage_2.csv\n",
    "* 顧客台帳データ（手入力で店舗が管理している顧客台帳）\n",
    "    * kokyaku_daicho_1.csv\n",
    "    * kokyaku_daicho_2.csv\n",
    "\n",
    "2つのファイルを用いて，以下に関する表を作成せよ：\n",
    "1. 縦方向にある年のある月，横方向に商品を並べた，商品ごとの年月別売上情報\n",
    "2. 縦方向にある年のある月，横方向に地域（市）を並べた，各市ごとの年月別売上情報\n",
    "3. 集計期間中（2019年1月〜2019年7月）に杏森堂で購買行動をしていない顧客のリスト\n",
    "\n",
    "\n",
    "※ なお，上記データは[Python実践データ分析100本ノック](https://www.amazon.co.jp/dp/4798058750/ref=cm_sw_r_tw_dp_QDCE479VPFEJZZTA4GQ5)のサンプルファイルの一部を加工したものである．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac62f7-3962-4ec5-a8d5-47a9588f29aa",
   "metadata": {},
   "source": [
    "---\n",
    "## ノック\n",
    "以下は上記課題を解くための要素を学ぶことができるクイズである．課題を解くためのスキルを着実に習得したい人は，以下のノックを順次解いてみよう．ノックの解説は授業中に行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb2d6f-442c-405d-86a0-b2b1ff387c00",
   "metadata": {},
   "source": [
    "### Knock 1: データの意味の確認\n",
    "購買記録に関するデータ（`uriage_1.csv`および`uriage_2.csv`）と顧客台帳データ（`kokyaku_daicho_1.csv`および`kokyaku_daicho_2.csv`）を開き，データの意味を確認せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b8f24-127f-42f8-adc8-4974d1b1e3bf",
   "metadata": {},
   "source": [
    "### Knock 2: データの揺れ，欠損値の確認\n",
    "購買記録に関するデータ（`uriage_1.csv`および`uriage_2.csv`）と顧客台帳データ（`kokyaku_daicho_1.csv`および`kokyaku_daicho_2.csv`）に含まれるデータの揺れや欠損値の有無を確認せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83178e8-f7da-4641-9409-7fdc9aa09cd6",
   "metadata": {},
   "source": [
    "### Knock 3: カラムの作成\n",
    "`uriage_1.csv`および`uriage_2.csv`のA列`purchase_date`の隣に`purchase_month`という列を作成し，A列のデータを`年/月`の形式に変換したデータを作成せよ．例えば，「2019/07/13 13:05:29」というデータであれば，「2019/07」というデータに変換したデータをB列に作成せよ．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0613b3-1d1a-4e11-b9a0-5bf65cedb624",
   "metadata": {},
   "source": [
    "### Knock 4: ピボットテーブル1 - 商品ごとの年月別売上データの個数の集計\n",
    "`uriage_1.csv`および`uriage_2.csv`を対象に，データの揺れや欠損値は補正せずに，\n",
    "* 縦軸に購入年月\n",
    "* 横軸に商品\n",
    "\n",
    "に並べた表を作成し，ある購入年月における各商品の売上データの個数を集計せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b9cd9-66c4-408d-877d-440be37b8b2a",
   "metadata": {},
   "source": [
    "### Knock 5: ピボットテーブル2 - 商品ごとの年月別売上金額の合計の集計\n",
    "`uriage_1.csv`および`uriage_2.csv`を対象にデータの揺れや欠損値は補正せずに，\n",
    "* 縦軸に購入年月\n",
    "* 横軸に商品\n",
    "\n",
    "に並べた表を作成し，ある購入年月における各商品の売上金額の合計値を集計せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c1428-8e8f-4f7a-adb7-e4602a0928b9",
   "metadata": {},
   "source": [
    "### Knock 6: データの揺れの補正\n",
    "`uriage_1.csv`および`uriage_2.csv`における商品名（`item_name`）の揺れを補正せよ．同様に，`kokyaku_daicho_1.csv`および`kokyaku_daicho_2.csv`における顧客名の揺れも補正せよ．補正対象は\n",
    "* スペースの有無\n",
    "* 半角・全角\n",
    "* アルファベットの大文字・小文字\n",
    "\n",
    "とする．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac827038-f300-49cd-a774-8c9dd256297d",
   "metadata": {},
   "source": [
    "### Knock 7: フィルタ操作 - 欠損値データの絞り込み\n",
    "`uriage_1.csv`および`uriage_2.csv`上のデータについて，商品価格（`item_price`）が欠損しているデータをリストアップせよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e5b11b-68d7-49c2-980a-ab8e1676f175",
   "metadata": {},
   "source": [
    "### Knock 8: 欠損値の補完\n",
    "`uriage_1.csv`および`uriage_2.csv`において，商品価格（`item_price`）の欠損値を同名の商品の商品価格で補完せよ．なお，商品名はKnock 6で揺れ補正をしたものを用いること．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9e223-bc85-4172-b40c-c7b749296011",
   "metadata": {},
   "source": [
    "### Knock 9: 結合\n",
    "`uriage_1.csv`および`uriage_2.csv`，と`kokyaku_daicho_1.csv`および`kokyaku_daicho_2.csv`を顧客名をキーにして結合し，1つの表を作成せよ．\n",
    "\n",
    "※ ヒント：Excel上で2つの表を結合するのは`VLOOKUP`関数を用いる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da53a9-4eaf-4a73-b0b2-606b65f011fc",
   "metadata": {},
   "source": [
    "### Knock 10: データ保存\n",
    "Knock 9で作成した表データを`dump.xlsx`というファイル名で保存せよ．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
